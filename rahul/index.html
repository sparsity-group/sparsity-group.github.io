<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="AncIbi6WH1u-WTOqfFH_ifUv8WbpzIVWNvrT_GjQ9vk"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Rahul Parhi | SPARSITY @ UCSD </title> <meta name="author" content="Rahul Parhi"> <meta name="description" content="Profile of Rahul Parhi"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?2c1bcb873573b3573b8097882b5c68c9"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sparsity.ucsd.edu/rahul/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <img height="25px" src="/assets/img/logo.svg" alt="SPARSITY @ UCSD"> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/papers/">Papers </a> </li> <li class="nav-item "> <a class="nav-link" href="/posts/">Posts </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Rahul Parhi </h1> <p class="desc">rahul <b>[at]</b> ucsd <b>[dot]</b> edu <br> Assistant Professor of <a href="https://www.ece.ucsd.edu/" rel="external nofollow noopener" target="_blank">ECE</a><a> at </a><a href="https://ucsd.edu/" rel="external nofollow noopener" target="_blank">UCSD</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rahul/rahul-epfl-bm-2023-480.webp 480w,/assets/img/rahul/rahul-epfl-bm-2023-800.webp 800w,/assets/img/rahul/rahul-epfl-bm-2023-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/rahul/rahul-epfl-bm-2023.jpg?d360e4158f355b62918eb2348f1e882c" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="rahul/rahul-epfl-bm-2023.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info">Jacobs Hall, Room 6406<br> 9736 Engineers Ln<br> La Jolla, CA 92093<br> </div> </div> <div class="clearfix"> <h3 id="about">About</h3> <p>I am an Assistant Professor of Electrical and Computer Engineering (<a href="https://www.ece.ucsd.edu/" rel="external nofollow noopener" target="_blank">ECE</a>) at the University of California, San Diego (<a href="https://ucsd.edu/" rel="external nofollow noopener" target="_blank">UCSD</a>), which I joined in 2024. From 2022 to 2024, I was a Postdoctoral Researcher at the École Polytechnique Fédérale de Lausanne (<a href="https://www.epfl.ch/en/" rel="external nofollow noopener" target="_blank">EPFL</a>), hosted by <a href="http://bigwww.epfl.ch/unser/" rel="external nofollow noopener" target="_blank">Michael Unser</a>. I completed my Ph.D. in 2022 at the University of Wisconsin–Madison (<a href="https://www.wisc.edu/" rel="external nofollow noopener" target="_blank">UW–Madison</a>), where I was supervised by <a href="https://nowak.ece.wisc.edu/" rel="external nofollow noopener" target="_blank">Robert D. Nowak</a>. I completed my undergraduate studies at the University of Minnesota, Twin Cities (<a href="https://twin-cities.umn.edu/" rel="external nofollow noopener" target="_blank">UMN</a>) in 2018.</p> <p>My research lies at the interface between functional analysis, signal processing, machine learning, nonparametric statistics, and optimization. My primary area of investigation is in the <strong>mathematics of data science</strong> with a focus on developing the foundations of <strong>neural networks</strong> and <strong>deep learning</strong>. Some questions my research aims to answer include:</p> <ol> <li>What is the effect of regularization in deep learning?</li> <li>What kinds of functions do neural networks learn?</li> <li>Why do neural networks seemingly break the curse of dimensionality?</li> <li>Why are neural networks able to adapt to low-dimensional structures?</li> </ol> <p>Other topics/keywords that catch my attention include <strong>compressed sensing</strong>, <strong>computed tomography</strong>, <strong>convex analysis</strong>, <strong>the geometry of Banach spaces</strong>, <strong>inverse problems</strong>, <strong>minimax rates</strong>, <strong>optimal recovery</strong>, <strong>sparsity</strong>, <strong>splines</strong>, <strong>time–frequency analysis</strong>, and <strong>wavelets</strong>. For more detailed information about my research, you can take a look at my <a href="/papers/">papers</a>.</p> <hr> <h3 id="selected-honors-and-awards">Selected Honors and Awards</h3> <ul> <li> <strong>(2024)</strong> Conference on Parsimony and Learning (CPAL) Rising Stars Award</li> <li> <strong>(2023)</strong> Harold Peterson Outstanding Dissertation Award from the University of Wisconsin–Madison</li> <li> <strong>(2020)</strong> NSF Graduate Research Fellowship <ul> <li>Awarded for the project titled <a href="/files/nsfgrfp-research.pdf">Bringing Approximation Theory to Data Science</a>.</li> </ul> </li> </ul> <hr> <h3 id="talks-and-presentations">Talks and Presentations</h3> <h4 id="tutorials">Tutorials</h4> <details><summary>A Function-Space Tour of Data Science (with <a href="https://gregongie.github.io/" rel="external nofollow noopener" target="_blank">Greg Ongie</a>) <a href="https://function-space-tour.github.io/cpal/" rel="external nofollow noopener" target="_blank"><strong>[</strong>website<strong>]</strong></a></summary> <ul> <li> <strong>(March 2025)</strong> Conference on Parsimony and Learning (CPAL)</li> </ul> </details> <p style="margin-bottom:0.5rem;"></p> <h4 id="invited-talks-in-university-seminars-and-colloquia">Invited Talks in University Seminars and Colloquia</h4> <details><summary>Function-Space Models for Deep Learning</summary> <ul> <li> <strong>(February 2025)</strong> PSU + Purdue + UMD, Joint Seminar on Mathematical Data Science</li> <li> <strong>(February 2025)</strong> Caltech, EE Seminar</li> <li> <strong>(January 2025)</strong> University of California, San Diego (UCSD), MINDS Seminar, Department of Mathematics</li> </ul> </details> <details><summary>Characteristic Functionals and the Innovations Approach to Stochastic Processes With Applications to Random Neural Networks <a href="/slides/cf-innovations-random-nn.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(February 2025)</strong> University of California, San Diego (UCSD), Probability Seminar, Department of Mathematics</li> </ul> </details> <details><summary>Deep Learning Meets Sparse Regularization <a href="/slides/deep-meets-sparse-job-talk.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(March 2024)</strong> Massachusetts Institute of Technology (MIT), EECS Seminar</li> <li> <strong>(February 2024)</strong> University of California, San Diego (UCSD), ECE Seminar</li> <li> <strong>(February 2024)</strong> University of Colorado, Boulder (CU Boulder), Applied Mathematics Seminar</li> <li> <strong>(February 2024)</strong> University of Alberta, CS Seminar</li> <li> <strong>(January 2024)</strong> Rutgers University, Mathematics Seminar</li> <li> <strong>(January 2024)</strong> Chinese University of Hong Kong, Shenzhen (CUHK–Shenzhen), SEE Seminar</li> <li> <strong>(December 2023)</strong> Washington University in St. Louis, ESE + SDS Seminar</li> <li> <strong>(December 2023)</strong> ETH Zürich, MINS Seminar</li> <li> <strong>(November 2023)</strong> Université Catholique de Louvain (UCLouvain), Statistics Seminar</li> <li> <strong>(September 2023)</strong> MPI MiS + UCLA, Math Machine Learning Seminar</li> </ul> </details> <details><summary>Regularizing Neural Networks via Radon-Domain Total Variation <a href="/slides/regularizing-radon-tv.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(November 2022)</strong> Johns Hopkins University, Mathematical Institute for Data Science (MINDS) Seminar</li> </ul> </details> <details><summary>What Kinds of Functions Do Neural Networks Learn? <a href="/slides/what-kinds-of-functions.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(November 2021)</strong> Working Group on Mean Field Neural Networks, Simons Institute for the Theory of Computing</li> </ul> </details> <details><summary>On BV Spaces, Splines, and Neural Networks</summary> <ul> <li> <strong>(November 2021)</strong> University of Wisconsin–Madison, Analysis Seminar, Department of Mathematics</li> </ul> </details> <details><summary>A Representer Theorem for Single-Hidden Layer Neural Networks</summary> <ul> <li> <strong>(July 2020)</strong> University of Wisconsin–Madison, Institute for Foundations of Data Science (IFDS) Seminar</li> </ul> </details> <details><summary>Neural Networks Learn Splines</summary> <ul> <li> <strong>(October 2019)</strong> University of Wisconsin–Madison, HAMLET Seminar</li> </ul> </details> <details><summary>Minimum “Norm” Neural Networks and Splines</summary> <ul> <li> <strong>(September 2019)</strong> University of Wisconsin–Madison, Institute for Foundations of Data Science (IFDS) Seminar</li> </ul> </details> <p style="margin-bottom:0.5rem;"></p> <h4 id="invited-talks-in-conference-sessions-and-minisymposia">Invited Talks in Conference Sessions and Minisymposia</h4> <details><summary>Deep Learning Meets Sparse Regularization <a href="/slides/deep-meets-sparse-short.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(November 2024)</strong> Canadian Mathematical Society (CMS) Winter Meeting, Mathematics of Machine Learning Session</li> </ul> </details> <details><summary>The Role of Sparsity in Learning With Overparameterized Deep Neural Networks <a href="/slides/role-sparsity-overparameterized.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(October 2024)</strong> SIAM Conference on Mathematics of Data Science (MDS), Learning Functions with Low-Dimensional Structure Using Neural Networks Minisymposium</li> </ul> </details> <details><summary>A Banach-Space View of Neural Network Training</summary> <ul> <li> <strong>(July 2024)</strong> International Symposium on Mathematical Programming (ISMP), Nonsmooth and Hierarchical Optimization in Machine Learning Session</li> </ul> </details> <details><summary>On the Sparsity-Promoting Effect of Weight Decay in Deep Learning <a href="/slides/sparsity-weight-decay.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(January 2024)</strong> Conference on Parsimony and Learning (CPAL), Rising Stars Session</li> </ul> </details> <details><summary>A Banach Space Representer Theorem for Single-Hidden Layer Neural Networks</summary> <ul> <li> <strong>(November 2020)</strong> SLowDNN Workshop, Young Researchers Spotlight Session</li> </ul> </details> <p style="margin-bottom:0.5rem;"></p> <h4 id="contributed-talks">Contributed Talks</h4> <details><summary>Modulation Spaces and the Curse of Dimensionality <a href="/slides/modulation-spaces-curse.pdf"><strong>[</strong>slides<strong>]</strong></a></summary> <ul> <li> <strong>(July 2023)</strong> International Conference on Sampling Theory and Applications (SampTA)</li> </ul> </details> <details><summary>On Continuous-Domain Inverse Problems with Sparse Superpositions of Decaying Sinusoids as Solutions</summary> <ul> <li> <strong>(May 2022)</strong> IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</li> </ul> </details> <hr> <h3 id="service-and-professional-activities">Service and Professional Activities</h3> <h4 id="journal-reviewer">Journal Reviewer</h4> <ul> <li>Annals of Statistics</li> <li>Applied and Computational Harmonic Analysis</li> <li>Biometrika</li> <li>IEEE Open Journal of Signal Processing</li> <li>IEEE Signal Processing Magazine</li> <li>IMA Journal of Applied Mathematics</li> <li>Integral Transforms And Special Functions</li> <li>Journal of Computational and Applied Mathematics</li> <li>Journal of Machine Learning Research</li> <li>Neural Networks</li> <li>SIAM Journal on Mathematical Analysis</li> <li>SIAM Journal on Mathematics of Data Science</li> <li>SIAM Journal on Scientific Computing</li> </ul> <h4 id="conference-and-workshop-reviewer">Conference and Workshop Reviewer</h4> <ul> <li>2020 Conference on Machine Learning and Systems (MLSys)</li> <li>2023, 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</li> <li>2025 International Conference on Artificial Intelligence and Statistics (AISTATS)</li> <li>2025 Learning for Dynamics &amp; Control Conference (L4DC)</li> <li>2025 ICLR Workshop on Weight Space Learning</li> </ul> <h4 id="conference-session-organizerchair">Conference Session Organizer/Chair</h4> <ul> <li>International Symposium on Mathematical Programming, Montréal, Québec, Canada, 2024 (<a href="https://ismp2024.gerad.ca/" rel="external nofollow noopener" target="_blank">ISMP 2024</a>) <ul> <li>Chair for the session on <a href="https://ismp2024.gerad.ca/schedule/FB/336" rel="external nofollow noopener" target="_blank">nonsmooth and hierarchical optimization in machine learning</a> </li> </ul> </li> <li>International Conference on Continuous Optimization, Los Angeles, California, 2025 (<a href="https://sites.google.com/view/iccopt2025" rel="external nofollow noopener" target="_blank">ICCOPT 2025</a>) <ul> <li>Organizer and chair for the session on relaxations of optimization problems and extreme point results in infinite dimensions</li> </ul> </li> </ul> <h4 id="internal-service-at-ucsd">Internal Service at UCSD</h4> <ul> <li>Teaching Innovations and Undergraduate Affairs Committee, Department of Electrical and Computer Engineering (2024 – Present)</li> </ul> <h4 id="other">Other</h4> <ul> <li>IEEE Member (2015, 2022 – Present)</li> <li>SIAM Member (2024 – Present)</li> <li>Regular contributor of <a href="https://www.ams.org/publications/math-reviews/math-reviews" rel="external nofollow noopener" target="_blank">Mathematical Reviews®</a> for <a href="https://mathscinet.ams.org/mathscinet/publications-search" rel="external nofollow noopener" target="_blank">MathSciNet®</a> (2024 – Present)</li> </ul> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?f3d41027dbdd52bc883bb3c267aec953"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FW68RKLGW"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-5FW68RKLGW");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>